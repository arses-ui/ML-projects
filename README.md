# Machine Learning Projects

A collection of machine learning implementations from scratch, covering fundamental algorithms and concepts.

## Projects

### 1. Linear Algebra Fundamentals
Core linear algebra implementations including:
- Matrix multiplication
- Matrix inverse (Gauss-Jordan elimination)
- Singular Value Decomposition (SVD)
- Moore-Penrose pseudo-inverse

### 2. Probability & Statistics
Statistical foundations for machine learning:
- Discrete and continuous random variables
- Bernoulli distribution
- Maximum Likelihood Estimation (MLE) vs Bayesian estimation
- Central Limit Theorem demonstration

### 3. Linear Regression & Gradient Descent
Regression analysis and optimization:
- Linear regression on real-world data (Detroit homicide rate prediction)
- Feature selection using projection methods
- Gradient descent with automatic differentiation (autograd)

### 4. SVM Multiclass Classification
Support Vector Machine implementation from scratch:
- Binary SVM with nonlinear polynomial kernels
- Convex optimization using CVXOPT
- One-vs-Rest (OVR) multiclass classification
- One-vs-One (OVO) multiclass classification
- Hyperparameter tuning (C parameter)
- Applied to MNIST digit classification (~94% accuracy)

### 5. Gradient Descent Optimization
Advanced optimization techniques:
- Full batch gradient descent
- Stochastic gradient descent (SGD)
- Mini-batch gradient descent
- Momentum optimization
- RMSprop optimization

## Technologies
- Python
- NumPy
- Matplotlib
- SciPy
- Autograd
- CVXOPT

## Author
Arses Prasai
